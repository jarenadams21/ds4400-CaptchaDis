{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile as wv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm # progress bar\n",
    "from audioMNIST import AudioMNIST\n",
    "from DClassifier import CNN2DAudioClassifier\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA device\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate(model, val_dl): \n",
    "    running_loss = 0.0\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "        \n",
    "    for data in tqdm(val_dl):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "        inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.to(device))\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, prediction = torch.max(outputs, 1)\n",
    "        correct_prediction += (prediction == labels).sum().item()\n",
    "        total_prediction += prediction.shape[0]\n",
    "\n",
    "    num_batches = len(val_dl)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    acc = correct_prediction / total_prediction\n",
    "\n",
    "    return acc, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def training(model, train_dl, val_dl, num_epochs, \n",
    "             criterion, optimizer, scheduler):\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "        \n",
    "        for data in tqdm(train_dl):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, prediction = torch.max(outputs, 1)\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "            \n",
    "        num_batches = len(train_dl)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        acc = correct_prediction / total_prediction\n",
    "        \n",
    "        v_acc, v_loss = evaluate(model.to(device), val_dl)\n",
    "        \n",
    "        print(\"Epoch: %d, Loss: %.4f, Train Accuracy: %.2f, Val. Loss: %.4f, Val. Accuracy: %.2f\" % (\n",
    "            epoch + 1, avg_loss, acc, v_loss, v_acc\n",
    "        ))\n",
    "        \n",
    "        losses.append(avg_loss)\n",
    "        val_losses.append(v_loss)\n",
    "        \n",
    "    return losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset = AudioMNIST()\n",
    "    train_dl = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    model = CNN2DAudioClassifier().to(device)\n",
    "    from torch.utils.data import random_split\n",
    "\n",
    "    # Training, Validation, Test Dataset Split\n",
    "    n_items = len(dataset)\n",
    "    n_train = round(n_items * 0.8)\n",
    "    n_val_test = n_items - n_train\n",
    "    train_ds, val_test_ds = random_split(dataset, [n_train, n_val_test])\n",
    "\n",
    "    n_val = round(n_val_test * 0.6)\n",
    "    n_test = n_val_test - n_val\n",
    "    val_ds, test_ds = random_split(val_test_ds, [n_val, n_test])\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        train_ds, batch_size=64, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    val_dl = torch.utils.data.DataLoader(\n",
    "        val_ds, batch_size=64, shuffle=False, num_workers=2\n",
    "    )\n",
    "\n",
    "    test_dl = torch.utils.data.DataLoader(\n",
    "        test_ds, batch_size=32, shuffle=False, num_workers=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                                max_lr=0.001, \n",
    "                                                steps_per_epoch=int(len(train_dl)), \n",
    "                                                epochs=N_EPOCHS, \n",
    "                                                anneal_strategy='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:26<00:00,  4.32it/s]\n",
      "100%|██████████| 57/57 [00:25<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.2786, Train Accuracy: 0.65, Val. Loss: 0.3706, Val. Accuracy: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:15<00:00,  4.96it/s]\n",
      "100%|██████████| 57/57 [00:22<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.1798, Train Accuracy: 0.96, Val. Loss: 0.1102, Val. Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:05<00:00,  5.75it/s]\n",
      "100%|██████████| 57/57 [00:24<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.0822, Train Accuracy: 0.98, Val. Loss: 0.0783, Val. Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:14<00:00,  5.02it/s]\n",
      "100%|██████████| 57/57 [00:24<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.0622, Train Accuracy: 0.98, Val. Loss: 0.0649, Val. Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses, val_losses = training(model, train_dl, val_dl, N_EPOCHS, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:23<00:00,  2.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9830555555555556, 0.06261319274965085)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "22d33a0debf81d76012e3fb50f9daecad1e12ff320a017e9164c9b4ad368a7e6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('space': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
